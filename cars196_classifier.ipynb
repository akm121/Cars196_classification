{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XlXkQ6qx_Xay"
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import os\n",
    "import random\n",
    "from pickle import load\n",
    "#from matplotlib.pylab import plt\n",
    "from numpy import arange\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYdee71UJDSF"
   },
   "source": [
    "# **Steps** <p>\n",
    "Step 1: Load Dataset <p>\n",
    "Step 2: Transform the Dataset <p>\n",
    "Step 3: Create Model <p>\n",
    "Step 4: Train Model <p>\n",
    "Step 5: Save the Model <p>\n",
    "Step 6: Load the Model <p>\n",
    "Step 7: Predict the Image <p>\n",
    "Step 8: Show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T7noSJhJUFr"
   },
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74CbnuuJAx4Y"
   },
   "outputs": [],
   "source": [
    "# Link of original dataset : https://www.kaggle.com/datasets/jutrera/stanford-car-dataset-by-classes-folder\n",
    "# The original data does not have a separate validation set. \n",
    "# Take out half of the test set to make a validation set.\n",
    "# The splitting is done uniformly across all the classes.\n",
    "\n",
    "data_dir = '/home/akm/Cars/Stanford_class/car_data/car_data'\n",
    "train_dir = data_dir + '/train' # n = 8144\n",
    "valid_dir = data_dir + '/valid' # n = 4021\n",
    "test_dir = data_dir + '/test' # n = 4020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO ONLY ONCE AT THE BEGINNING\n",
    "'''\n",
    "source = '/home/akm/Cars/Stanford_class/car_data/car_data/test'\n",
    "\n",
    "destination = '/home/akm/Cars/Stanford_class/car_data/car_data/valid'\n",
    "\n",
    "alldirs = os.listdir(source)\n",
    "\n",
    "for i in range(len(alldirs)):\n",
    "    dirpath = os.path.join(source,alldirs[i])\n",
    "    allfiles = os.listdir(dirpath)\n",
    "    allfiles_dic = {x : allfiles[x] for x in range(len(allfiles))}\n",
    "    \n",
    "    num_samples = len(allfiles)\n",
    "    num_valid = int(round(num_samples * 0.5))\n",
    "    valid_indexes = random.sample(range(num_samples), num_valid)\n",
    "    validfiledic = []\n",
    "    validfiledic = {x : allfiles[x] for x in valid_indexes}\n",
    "    for key in validfiledic:\n",
    "        src_path = os.path.join(dirpath, validfiledic[key])\n",
    "        dst_dir = os.path.join(destination,alldirs[i])\n",
    "        if not os.path.exists(dst_dir):\n",
    "                    os.makedirs(dst_dir)\n",
    "        dst_path = os.path.join(destination,alldirs[i], validfiledic[key])\n",
    "        #print(key, validfiledic[key],dirpath, src_path, dst_dir, dst_path)\n",
    "        shutil.move(src_path, dst_path)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLysmbnmJemX"
   },
   "source": [
    "## Step 2: Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOqT-9GXA8F_"
   },
   "outputs": [],
   "source": [
    "# Training transform includes random rotation and flip to build a more robust model\n",
    "train_transforms = transforms.Compose([transforms.Resize((244,244)), # all pretrained models take 244*244 image as input, except for inception_v3 which takes 299*299\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# The validation set will use the same transform as the test set\n",
    "test_transforms = transforms.Compose([transforms.Resize((244,244)), # all pretrained models take 244*244 image as input, except for inception_v3 which takes 299*299\n",
    "                                      transforms.CenterCrop(224), # for inception_v3 this needs to be removed\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize((244,244)), # all pretrained models take 244*244 image as input, except for inception_v3 which takes 299*299\n",
    "                                            transforms.CenterCrop(224), # for inception_v3 this needs to be removed\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(data_dir + '/valid', transform=validation_transforms)\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "# The trainloader will have shuffle=True so that the order of the images do not affect the model\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M265WLOdJ3xV"
   },
   "source": [
    "## Step 3: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1emIi-zkXNz1",
    "outputId": "2a93d3d5-0c02-42c9-b596-667df7cb2327",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "#model = models.vgg16(pretrained=True)\n",
    "#model = models.vgg19(pretrained=True)\n",
    "#model = models.googlenet(pretrained=True)\n",
    "#model = models.inception_v3(pretrained=True)\n",
    "#model = models.resnet18(pretrained=True)\n",
    "#model = models.resnet34(pretrained=True)\n",
    "#model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZcqibDULVbil",
    "outputId": "a4ecd4de-6a83-4c43-b141-e63791e084a2"
   },
   "outputs": [],
   "source": [
    "# Change final outputs to the number of classes i.e., 196 from previous 1000 classes (the number of output classes in imagenet)\n",
    "# Different pretrained models have different architectures and the fully connected layers are named differently\n",
    "# Need to consider case by case\n",
    "# For models that have single fully connected layer, we change final output nodes to 196\n",
    "# For models with more than 1 fully connected layer, we change final output nodes to 196 and second last layer to have 1024 output nodes to keep number of trainable parameters low\n",
    "\n",
    "# For alexnet\n",
    "model.classifier[4] = nn.Linear(4096,1024)\n",
    "model.classifier[6] = nn.Linear(1024,196)\n",
    "\n",
    "# For vgg16 and vgg19\n",
    "#model.classifier[3] = nn.Linear(4096,1024)\n",
    "#model.classifier[6] = nn.Linear(1024,196)\n",
    "\n",
    "# For googlenet\n",
    "#model.fc = nn.Linear(1024, 196\n",
    "\n",
    "# For inceptionv3 \n",
    "#model.aux_logits=False\n",
    "#model.fc = nn.Linear(2048, 196)\n",
    "\n",
    "# For resnet18 and resnet34\n",
    "#model.fc = nn.Linear(512, 196)\n",
    "\n",
    "# For resnet50 and \n",
    "#model.fc = nn.Linear(2048, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZQGN3U1tWu0"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1j802WQKhRa"
   },
   "source": [
    "## Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7OXITrCGu5J"
   },
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, validloader, criterion):\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # change model to work with cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Iterate over data from validloader\n",
    "    for ii, (images, labels) in enumerate(validloader):\n",
    "    \n",
    "        # Change images and labels to work with cuda\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass image though model for prediction\n",
    "        output = model.forward(images)\n",
    "        # Calculate loss\n",
    "        valid_loss += criterion(output, labels).item()\n",
    "        # Calculate probability\n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "eBpYU-KpuyFq",
    "outputId": "3f37ee6f-571b-4d84-9efa-9b88a9505692",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "print_every = 40\n",
    "train_dic = {}\n",
    "valid_dic = {}\n",
    "\n",
    "# change to gpu mode\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    # Iterating over data to carry out training step\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # zeroing parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Carrying out validation step\n",
    "        if steps % print_every == 0:\n",
    "            # setting model to evaluation mode during validation\n",
    "            model.eval()\n",
    "            \n",
    "            # Gradients are turned off as no longer in training\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
    "            \n",
    "            # Turning training back on\n",
    "            model.train()\n",
    "            lrscheduler.step(accuracy * 100)\n",
    "    print(f\"No. epochs: {e+1}, \\\n",
    "    Training Loss: {round(running_loss/print_every,3)} \\\n",
    "    Valid Loss: {round(valid_loss/len(validloader),3)} \\\n",
    "    Valid Accuracy: {round(float(accuracy/len(validloader)),3)}\")\n",
    "            \n",
    "    train_dic[e+1] = round(running_loss/print_every,3)\n",
    "    valid_dic[e+1] = round(valid_loss/len(validloader),3)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise training plot\n",
    "\n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_dic.values()\n",
    "val_values = valid_dic.values()\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, 11)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_values, label='Training Loss')\n",
    "plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(arange(0, 11, 1))\n",
    "\n",
    "#plt.plot(figsize=(20, 10))\n",
    "\n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cXyFWRKJIaqU",
    "outputId": "9c721d83-bc50-4a6d-bbc1-5cc8d5fc8c5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "model.to('cuda')\n",
    "actual_class = []\n",
    "predicted_class = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        # Get probabilities\n",
    "        outputs = model(images)\n",
    "        # Turn probabilities into predictions\n",
    "        _, predicted_outcome = torch.max(outputs.data, 1)\n",
    "        # Total number of images\n",
    "        total += labels.size(0)\n",
    "        # Count number of cases in which predictions are correct\n",
    "        correct += (predicted_outcome == labels).sum().item()\n",
    "        \n",
    "        actual_class.append(labels.tolist())\n",
    "        predicted_class.append(predicted_outcome.tolist())\n",
    "\n",
    "print(f\"Test accuracy of model: {round(100 * correct / total,3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test prediction in a list of lists\n",
    "\n",
    "def flat(lis):\n",
    "    flatList = []\n",
    "    # Iterate with outer list\n",
    "    for element in lis:\n",
    "        if type(element) is list:\n",
    "            # Check if type is list than iterate through the sublist\n",
    "            for item in element:\n",
    "                flatList.append(item)\n",
    "        else:\n",
    "            flatList.append(element)\n",
    "    return flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test prediction in a array list\n",
    "\n",
    "actual_class_flat = np.array(flat(actual_class))\n",
    "predicted_class_flat = np.array(flat(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data of lists.\n",
    "data_pred = {'Actual': actual_class_flat,\n",
    "        'Predcited': predicted_class_flat}\n",
    "  \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_pred)\n",
    "  \n",
    "# Print the output.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier saving and loading define model_var as the name of model\n",
    "\n",
    "model_var = \"alexnet\" # alexnet, vgg16, vgg19, googlenet, inception_v3, resnet18, resnet34, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var +'_actual_predcited.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dekV68M3Kufx"
   },
   "source": [
    "## Step 5: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vcTL2RZBdDk"
   },
   "outputs": [],
   "source": [
    "# Saving: feature weights, new model.fc, index-to-class mapping, optimiser state, and No. of epochs\n",
    "# Applicable for googlenet, inception_v3, resnet18, resnet34, resnet50\n",
    "checkpoint = {'state_dict': model.state_dict(),\n",
    "              'model': model.fc,\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'opt_state': optimizer.state_dict,\n",
    "              'num_epochs': epochs}\n",
    "\n",
    "torch.save(checkpoint, '/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var + '_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving: feature weights, new model.fc, index-to-class mapping, optimiser state, and No. of epochs\n",
    "# Applicable for alexnet, vgg16, vgg19\n",
    "checkpoint = {'state_dict': model.state_dict(),\n",
    "              'model': model.classifier,\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'opt_state': optimizer.state_dict,\n",
    "              'num_epochs': epochs}\n",
    "\n",
    "torch.save(checkpoint, '/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var + '_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PM9BMpgxK5pe"
   },
   "source": [
    "## Step 6: Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import os\n",
    "import random\n",
    "from pickle import load\n",
    "#from matplotlib.pylab import plt\n",
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3uxYcS4Lo0D"
   },
   "outputs": [],
   "source": [
    "# Write a function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "#model = models.vgg16(pretrained=True)\n",
    "#model = models.vgg19(pretrained=True)\n",
    "#model = models.googlenet(pretrained=True)\n",
    "#model = models.inception_v3(pretrained=True)\n",
    "#model = models.resnet18(pretrained=True)\n",
    "#model = models.resnet34(pretrained=True)\n",
    "#model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change final outputs to the number of classes i.e., 196 from previous 1000 classes (the number of output classes in imagenet)\n",
    "# Different pretrained models have different architectures and the fully connected layers are named differently\n",
    "# Need to consider case by case\n",
    "# For models that have single fully connected layer, we change final output nodes to 196\n",
    "# For models with more than 1 fully connected layer, we change final output nodes to 196 and second last layer to have 1024 output nodes to keep number of trainable parameters low\n",
    "\n",
    "# For alexnet\n",
    "model.classifier[4] = nn.Linear(4096,1024)\n",
    "model.classifier[6] = nn.Linear(1024,196)\n",
    "\n",
    "# For vgg16 and vgg19\n",
    "#model.classifier[3] = nn.Linear(4096,1024)\n",
    "#model.classifier[6] = nn.Linear(1024,196)\n",
    "\n",
    "# For googlenet\n",
    "#model.fc = nn.Linear(1024, 196\n",
    "\n",
    "# For inceptionv3 \n",
    "#model.aux_logits=False\n",
    "#model.fc = nn.Linear(2048, 196)\n",
    "\n",
    "# For resnet18 and resnet34\n",
    "#model.fc = nn.Linear(512, 196)\n",
    "\n",
    "# For resnet50 and \n",
    "#model.fc = nn.Linear(2048, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dbACQoOmN1Dp",
    "outputId": "b913c74c-7624-4c50-80d6-b6aa105cd5f0"
   },
   "outputs": [],
   "source": [
    "# Loading model\n",
    "\n",
    "model_var = \"alexnet\" # alexnet, vgg16, vgg19, googlenet, inception_v3, resnet18, resnet34, resnet50\n",
    "\n",
    "model = load_checkpoint('/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var + '_checkpoint.pth')\n",
    "# Checking model i.e. should have 196 output units in the classifier\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFnIGydILDh8"
   },
   "source": [
    "## Step 7: Predict the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4-5e6f-XzPW"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    # Converting image to PIL image using image file path\n",
    "    pil_im = Image.open(f'{image}' + '.jpg')\n",
    "\n",
    "    # Building image transform\n",
    "    transform = transforms.Compose([transforms.Resize((244,244)), # all pretrained models take 244*244 image as input, except for inception_v3 which takes 299*299\n",
    "                                    transforms.CenterCrop(224), # for inception_v3 this needs to be removed\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                         [0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    # Transforming image for use with network\n",
    "    pil_tfd = transform(pil_im)\n",
    "    \n",
    "    # Converting to Numpy array \n",
    "    array_im_tfd = np.array(pil_tfd)\n",
    "    \n",
    "    return array_im_tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rH4Elba-CNnD"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/akm/Cars/Stanford_class/car_data/car_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "1t3KpW8MCdD1",
    "outputId": "5b16dd26-b5ac-4138-9321-32ec8d47accf"
   },
   "outputs": [],
   "source": [
    "imshow(process_image(data_dir + '/test/' + 'Tesla Model S Sedan 2012' + '/07305'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3tTW5LeC5UJ"
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    # Implement the code to predict the class from an image file   \n",
    "    \n",
    "    # Loading model - using .cpu() for working with CPUs\n",
    "    loaded_model = load_checkpoint(model).cpu()\n",
    "    # Pre-processing image\n",
    "    img = process_image(image_path)\n",
    "    # Converting to torch tensor from Numpy array\n",
    "    img_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "    # Adding dimension to image to comply with (B x C x W x H) input of model\n",
    "    img_add_dim = img_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Setting model to evaluation mode and turning off gradients\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Running image through network\n",
    "        output = loaded_model.forward(img_add_dim)\n",
    "        \n",
    "    #conf, predicted = torch.max(output.data, 1)   \n",
    "    probs_top = output.topk(topk)[0]\n",
    "    predicted_top = output.topk(topk)[1]\n",
    "    \n",
    "    # Converting probabilities and outputs to lists\n",
    "    conf = np.array(probs_top)[0]\n",
    "    predicted = np.array(predicted_top)[0]\n",
    "        \n",
    "    #return probs_top_list, index_top_list\n",
    "    return conf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mnMLifs1xkFH",
    "outputId": "43f660ac-f595-4844-c523-2b279ec0b018",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tie the class indices to their names\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "classes, c_to_idx = find_classes(data_dir+\"/train\")\n",
    "\n",
    "print(classes, c_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var  +'_checkpoint.pth'\n",
    "image_path = data_dir + '/test/' + 'Tesla Model S Sedan 2012' + '/07305'\n",
    "\n",
    "\n",
    "conf1, predicted1 = predict(image_path, model_path, topk=5)\n",
    "\n",
    "print(conf1)\n",
    "print(classes[predicted1[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(cardir, model):\n",
    "  # Testing predict function\n",
    "\n",
    "  # Inputs are paths to saved model and test image\n",
    "  model_path = '/home/akm/Cars/Stanford_class/car_data/car_data/' + model_var + '_checkpoint.pth'\n",
    "  image_path = cardir\n",
    "  carname = cardir.split('/')[8]\n",
    "\n",
    "  conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "  # Converting classes to names\n",
    "  names = []\n",
    "  for i in range(5):\n",
    "  \n",
    "      names += [classes[predicted1[i]]]\n",
    "\n",
    "\n",
    "  # Creating PIL image\n",
    "  image = Image.open(image_path+'.jpg')\n",
    "\n",
    "  # Plotting test image and predicted probabilites\n",
    "  f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "  ax[0].imshow(image)\n",
    "  ax[0].set_title(carname)\n",
    "\n",
    "  y_names = np.arange(len(names))\n",
    "  ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "  ax[1].set_yticks(y_names)\n",
    "  ax[1].set_yticklabels(names)\n",
    "  ax[1].invert_yaxis() \n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cardir= (data_dir + '/test/' + 'Tesla Model S Sedan 2012' + '/07305')\n",
    "plot_solution(cardir, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cars model classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
